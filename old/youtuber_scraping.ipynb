{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "無効な数字が選ばれました！\n",
      "Start vector...\n",
      "add video_id:  8Gmj2sv39hY\n",
      "add video_id:  AysXcHKx5RM\n",
      "add video_id:  U2dbNWdWMSY\n",
      "start faiss vector...\n",
      "faiss vector complete!\n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import csv\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "import os\n",
    "from llama_index.langchain_helpers.text_splitter import TokenTextSplitter\n",
    "import tiktoken\n",
    "from langchain.schema import Document\n",
    "import pandas as pd\n",
    "\n",
    "#環境変数読み込み\n",
    "load_dotenv('../.env')\n",
    "\n",
    "#新しい順からビデオを取り込む\n",
    "def get_script_date(youtuber_name, channel_id, from_date, youtube):\n",
    "    print(\"新しい順に取得\")\n",
    "    res = youtube.channels().list(id=channel_id, part='contentDetails').execute()\n",
    "    playlist_id = res['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    videos = []\n",
    "    next_page_token = None\n",
    "    while True:\n",
    "        res = youtube.playlistItems().list(playlistId=playlist_id,\n",
    "                                        part='contentDetails',\n",
    "                                        maxResults=50,\n",
    "                                        pageToken=next_page_token).execute()\n",
    "        videos += res['items']\n",
    "        next_page_token = res.get('nextPageToken')\n",
    "        if next_page_token is None:\n",
    "            break\n",
    "    \n",
    "    #日時で指定\n",
    "    videos = [video for video in videos if datetime.strptime(video['snippet']['publishedAt'], \"%Y-%m-%dT%H:%M:%SZ\") > from_date]\n",
    "    \n",
    "    for video in videos:\n",
    "        # print(video['snippet'])\n",
    "        video_id = video['snippet']['resourceId']['videoId']\n",
    "        vidoe_title = video['snippet']['title']\n",
    "        video_description = video['snippet']['description']\n",
    "        video_date = video['snippet']['publishedAt']\n",
    "        print('Fetching subtitles for ', video_id)\n",
    "        try:\n",
    "            srt = YouTubeTranscriptApi().get_transcript(video_id, languages=['ja'])\n",
    "            transcript = '\\n'.join([chunk[\"text\"] for chunk in srt])\n",
    "            \n",
    "            #字幕から余分な要素を取り除く\n",
    "            transcript = transcript.replace(\"[音楽]\", \"\")\n",
    "            transcript = transcript.replace(\"\\n\", \"\")\n",
    "            \n",
    "            #フォルダ作成\n",
    "            folder_pass = os.path.join(os.getcwd(), \"raw_data\", youtuber_name)\n",
    "            if not os.path.exists(folder_pass):\n",
    "                print(\"フォルダ作成:\", folder_pass)\n",
    "                os.makedirs(folder_pass)\n",
    "            save_pass = os.path.join(os.getcwd(), \"raw_data\", youtuber_name, f'{video_id}.csv')\n",
    "            with open(save_pass, 'w', encoding='utf-8', newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerows(\n",
    "                    [['video_id', video_id],\n",
    "                    ['video_title', vidoe_title],\n",
    "                    ['video_description', video_description],\n",
    "                    ['video_date', video_date],\n",
    "                    ['transcript', transcript]]\n",
    "                    )\n",
    "                # writer.writerow([video_id, vidoe_title, video_description, video_date, transcript])\n",
    "        except Exception as e:\n",
    "            print('Could not fetch subtitles for ', video_id, ': ', str(e))\n",
    "        print(\"処理完了\")\n",
    "\n",
    "#再生回数順で取得(なぜか性格にできない・・・、ずっと昔の動画はチャンネルIDが変わっている影響？)\n",
    "def get_script_number_of_play(youtuber_name, channel_id, youtube, max_number):\n",
    "    print(\"再生回数順に取得\")\n",
    "    # while True:\n",
    "    res = youtube.search().list(\n",
    "        channelId=channel_id,\n",
    "        part='snippet',\n",
    "        maxResults=max_number,\n",
    "        order='viewCount'\n",
    "        ).execute()\n",
    "    videos = res['items']\n",
    "    \n",
    "    for video in videos:\n",
    "        video_id = video['id']['videoId']\n",
    "        vidoe_title = video['snippet']['title']\n",
    "        video_description = video['snippet']['description']\n",
    "        video_date = video['snippet']['publishedAt']\n",
    "        print('Fetching subtitles for ', video_id)\n",
    "        try:\n",
    "            srt = YouTubeTranscriptApi().get_transcript(video_id, languages=['ja'])\n",
    "            transcript = '\\n'.join([chunk[\"text\"] for chunk in srt])\n",
    "            \n",
    "            #字幕から余分な要素を取り除く\n",
    "            transcript = transcript.replace(\"[音楽]\", \"\")\n",
    "            transcript = transcript.replace(\"\\n\", \"\")\n",
    "            \n",
    "            #フォルダ作成\n",
    "            folder_pass = os.path.join(os.getcwd(), \"raw_data\", youtuber_name)\n",
    "            if not os.path.exists(folder_pass):\n",
    "                print(\"フォルダ作成:\", folder_pass)\n",
    "                os.makedirs(folder_pass)\n",
    "            save_pass = os.path.join(os.getcwd(), \"raw_data\", youtuber_name, f'{video_id}.csv')\n",
    "            with open(save_pass, 'w', encoding='utf-8', newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerows(\n",
    "                    [['video_id', video_id],\n",
    "                    ['video_title', vidoe_title],\n",
    "                    ['video_description', video_description],\n",
    "                    ['video_date', video_date],\n",
    "                    ['transcript', transcript]]\n",
    "                    )\n",
    "                # writer.writerow([video_id, vidoe_title, video_description, video_date, transcript])\n",
    "        \n",
    "        except Exception as e:\n",
    "            print('Could not fetch subtitles for ', video_id, ': ', str(e))\n",
    "        print(\"処理完了\")\n",
    "        \n",
    "        \n",
    "        \n",
    "def youtuber_scraping():\n",
    "    \"\"\"\n",
    "    Youtuberの字幕データを収集する。\n",
    "    \"\"\"\n",
    "    #環境変数確認\n",
    "    if os.getenv(\"YOUTUBE_API\") == None:\n",
    "        print(\"環境変数が設定されていません。.envの中身と場所を確認してください。\")\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        YOUTUBE_API = os.getenv(\"YOUTUBE_API\")\n",
    "        #csvからの情報読み取り\n",
    "        df = pd.read_csv(\"./youtuber_info.csv\")\n",
    "        youtuber_name = df['youtuber_name'].values.tolist()\n",
    "        youtuber_id = df['youtuber_id'].values.tolist()\n",
    "        scraping_method = df['scraping_method'].values.tolist()\n",
    "        scraping_year = df['scraping_year'].values.tolist()\n",
    "        scraping_month = df['scraping_month'].values.tolist()\n",
    "        scraping_date = df['scraping_date'].values.tolist()\n",
    "        max_number = df['max_number'].values.tolist()\n",
    "        \n",
    "        #読み込んだリストからの処理\n",
    "        for i in range(len(youtuber_name)):\n",
    "            #youtubeのモジュール読み込み\n",
    "            youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=YOUTUBE_API)\n",
    "            if scraping_method[i] == 1:\n",
    "                get_script_date(\n",
    "                    youtuber_name=youtuber_name[i],\n",
    "                    channel_id=youtuber_id[i],\n",
    "                    from_date=datetime(scraping_year[i], scraping_month[i], scraping_date[i]),\n",
    "                    youtube=youtube\n",
    "                    )\n",
    "            elif scraping_method[i] == 2:\n",
    "                get_script_number_of_play(\n",
    "                    youtuber_name=youtuber_name[i],\n",
    "                    channel_id=youtuber_id[i],\n",
    "                    youtube=youtube,\n",
    "                    max_number=max_number[i]\n",
    "                )\n",
    "            \n",
    "            else:\n",
    "                print(\"無効な数字が選ばれました！scraping method: 1.新しい順に動画を取得 2.再生回数順に動画を取得\")\n",
    "                break\n",
    "            # ベクトル化処理\n",
    "            print(\"Start vector...\")\n",
    "            # ベクトルを保存するディレクトリ\n",
    "            vector_folder_path = os.path.join(os.getcwd(), \"vector_store\", youtuber_name[i])\n",
    "            \n",
    "            #FAISSのembeddingを定義\n",
    "            model_name = model_name=\"intfloat/multilingual-e5-large\"\n",
    "            # model_kwargs = {'device': 'cuda'} #GPUでembedding\n",
    "            model_kwargs = {'device': 'cpu'} #CPUでembedding\n",
    "            hf_embeddings = HuggingFaceBgeEmbeddings(\n",
    "                model_name = model_name,\n",
    "                model_kwargs = model_kwargs,\n",
    "            )\n",
    "            \n",
    "            text_splitter = TokenTextSplitter(\n",
    "                separator=\" \",\n",
    "                chunk_size=128,\n",
    "                chunk_overlap=20,\n",
    "                tokenizer=tiktoken.get_encoding(\"cl100k_base\").encode)\n",
    "\n",
    "            # 取り入れたデータを読み込む\n",
    "            data_filepath = os.path.join(os.getcwd(), \"raw_data\", youtuber_name[i])\n",
    "            data_list = os.listdir(data_filepath)\n",
    "            raw_data_dict_list = []\n",
    "            for data in data_list:\n",
    "                with open(os.path.join(data_filepath, data), mode=\"r\", encoding='utf-8') as f:\n",
    "                    reader = csv.reader(f)\n",
    "                    dict_from_csv = {rows[0]: rows[1] for rows in reader}\n",
    "                    raw_data_dict_list.append(dict_from_csv) # raw_data_dict_listには辞書形式で動画の情報が入っている\n",
    "            document_list = []\n",
    "            for raw_data_dict in raw_data_dict_list:\n",
    "                transcript = raw_data_dict['transcript']\n",
    "                video_id = raw_data_dict['video_id']\n",
    "                video_title = raw_data_dict['video_title']\n",
    "                video_description = raw_data_dict['video_description']\n",
    "                video_date = raw_data_dict['video_date']\n",
    "                # 字幕を分割\n",
    "                split_transcript_list = text_splitter.split_text(transcript)\n",
    "                for split_transcript in split_transcript_list:\n",
    "                    document_list.append(Document(\n",
    "                        page_content=split_transcript,\n",
    "                        metadata={\n",
    "                            'video_id':video_id,\n",
    "                            'video_titile':video_title,\n",
    "                            'video_description':video_description,\n",
    "                            'video_date':video_date,\n",
    "                        }\n",
    "                    ))\n",
    "                print('add video_id: ', video_id)\n",
    "            #FAISSのベクトル化\n",
    "            print('start faiss vector...')\n",
    "            faiss_vectorstore = FAISS.from_documents(document_list, embedding=hf_embeddings)\n",
    "            print('faiss vector complete!')\n",
    "            if not os.path.exists(os.path.join(vector_folder_path, \"faiss\")):\n",
    "                os.makedirs(os.path.join(vector_folder_path, \"faiss\"))\n",
    "            faiss_vectorstore.save_local(folder_path=os.path.join(vector_folder_path, \"faiss\"))\n",
    "    \n",
    "youtuber_scraping()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_id': 'y7bC-ylbStY', 'video_title': 'アドバイスの取捨選択をどうするか。', 'video_description': 'アンバランスを理解して保有できないと一生間違う。\\n\\n【宋世羅のオンラインサロン詳細はこちら】\\nhttps://lounge.dmm.com/detail/3350/\\n新卒、スーパーセールス、営業以外の方まで、様々います。\\n宋世羅と近い距離で接したい、また、メンバー同士でも熱く交流したい方お待ちしています。\\n\\n【宋世羅への保険面談問い合わせはこちらから】\\nhttps://sonsera.net/mendan/\\n宋世羅本人が保険面談へ伺います。お問い合わせお待ちしています。\\n\\n【宋世羅 著『一生使える「勝ちメンタル」のつくり方』購入はこちらから】\\nhttps://amzn.to/3H1jdKy\\n\\n【宋世羅 著『ヨイショする営業マンは全員アホ』購入はこちらから】\\nhttps://amzn.to/3kmUWnv', 'video_date': '2023-12-22T12:49:21Z', 'transcript': 'はいそンです今日はアドバイスの主者選択というテーマでお話ししますで私の森証券の4年間保険の営業マとして6年半ずっと営業してまして今日はですね超感覚ベリミックス的なお話なんですけどま皆さんですね会社の上司だとかまたは部活のコーチとかですねまたは今情報社会なんでなんかYouTubeとか本とかでなんかこうやったら金稼げるって言ってるみたいなこうやったら営業うまくいくって言ってるみたいなこういう情報は死ぬほど流れてきたりだとかアドバイス受けると思うんですねでその時にそのアドバイスをま受け入れるのか受け入れないのかっていうこの選択のところすねでここバチバチのセンス出ると思ってましてでここですねなんか両方いると思ってましてどういうことかって言うと素直にアドバイスを受け入れて崩れていくパターンっていうのもあると思うんすねこれ私大学野球部で野球やってたんですけどこれなるやつめっちゃ多いんですねなんかこう監督高知から技術指導されてそれ取り入れてなんか余計おかしなるみたいなでなんかこう旗から見ればうわああいつなんかミスったなみたいなよりぐちゃぐちゃなってんじゃんていうかなんかもう取り入れたからこそぐちゃぐちゃなってんじゃんみたいな周りから見てこう見えるパターンすねで一方で頑固で一生間違ったことをやるパターンっていうのもあると思うんですねああいつはもうアドバイスとか聞かねえし言ったことやらんとだから自分のやり方で一生成長しない間違った感じでずっとやり続けてるみたいなだからあいつは伸びないんだみたいなこういうパターンも結構あると思うんですねでなんか世の中この素直お頑固みたいなここでなんか0100で雑に決めてるんですけど素直はいいとか悪いとか頑固は悪いとかいいとかなんかこういう感じ簡単に決めてるんですけどこれ両パターンあるんで頑固だからこそ好転したみたいな素直だから失敗したみたいなこういうのも結構あると思うんでじゃこの辺の結局主催選択のセンスだと思うんすねでこのまアドバイスなり情報の死者選択をどうやっていけばいいのかっていうのをもうドラの偏見でお話ししていきますとでまずアドバイスもらったりだとかですねなんかこれをやった方がいいみたいなこういう情報が流れ込んできた時に4つ軸があると思ってましてまず1個が正しいか間違ってるかっていう結構まロジック的というか合理的というかそのアドバイスがシンプルに言ってることが正しいのか間違ってるのかっていうこれが1つともう1個ができそうかできなさそうかっていうこういう軸もあるんですねで3つ目がやりたいかやりたくないかっていうこういう軸もありますとで最後自分に愛そうか合わなさそうかっていうこの4つがあって主催選択見するやつてですねこの4つを同時に考えちゃうんすねで1番目の正しいか間違ってるかっていうのは結構まロジック的な話というかフラットに考えて合理的に考えてみたいなこういう匂いがするんですけどそれ以外の出きそうかできなさそうかとかやりたいかやりたくないかとかこの辺って結構感情っていう話なんですね自分にとってうん俺はなんとなくこう思うみたいなこういう結構自分の感情論であると思うんすけどでこれを全部一緒に考えてるやつってですねどういう現象が起きるかって言うと本来ロジックだとか合理的に考えてそれは正しいとこのおっさんが言ってるアドバイスは正しいけど自分にとってできそうにないっていうこの正しいできそうにないっていうこういう組み合わせが来た時にこれちょっとひねくれてるいわゆるあのシーフードピヨピオですねこういうシーフードピヨピってこの正しいできそうにないを間違ってるっていうこういう風にすり替えちゃうんですねでこれやるやつアホでまずですね順番として一旦感情的なところを抜くんですねまずは超フラットに自分ができそうとかできなさそうとかやりたいとかやりたくないとか全部一旦無視してそのアドバイスなりま言ってることがロジックとして正しいか間違ってるかっていうここをまず判断しにくんですねで一旦そこだけ考えれば結構答え出せると思うんすねほぼほぼ外さないみたいな感覚があるんですけどこれをさっき言ったシーフードピヨピオみたいにごっちゃに考えるとまず1番目の正しい間違ってるっていうここの正解をもう引きづらくなるんですねうんできそうやけどやりたくないで自分に合ってなさそうだからこいつの言ってることは間違ってるみたいな一気に最初の正しい間違ってるを外しやすがあるみたいなイメージですねで頭ええやつってですねここをなんか分けて考えれてるというかまず一旦できそうとか全部抜かして感情論抜いて正しい間違ってるうんま確かにこの人の言う通りやな正しいけどこれはできそうにないっていうこの正しいできそうにないっていうこういうポジションで認識できてそれを引き出しの中に一旦保有し続けられるみたいなだからここをなんかこう分けて保有できてるやつってまもちろん出射選択のセンスもあると思いますしまま相手にとってもイラっとされないですねあ確かに先輩の言ってることは正しいですとで僕自身やりたいと思ってますとけどできそうにありませんていうなんかここまでちゃんと正直に対応できるやつがま相手にとってイラっとされないっていうのもありますしさっき言ったできなさそうだから間違ってるみたいなこういうぶった切りをしてないんで引き出しの1つとして溜まっていくんですねだからなんか今後の判断基準とかにも色々こう考える材料として使いやすいというかまよって成長しやすいみたいななんかこういうイメージもありますとなんでこれ全国の営業ま本当汗下たり落ちるぐらい分かるお話だと思うんですけど営業現場でですねお客様にこうなんか商品こう提案してですねうみたいな感じになってる時にお客様自身これを例えば買った方がいいと正しいっていうことは分かってるんだけどもけど決断できそうにないっていうこういう正しい決断できなさそうっていうこういう組み合わせがあった時にこれを間違ってるっていうこういう風にずっと言ってくるお客様ていると思うんすねでま実際まあなんかここでこう詰めるのか詰めないのかって言うとま実際営業現場ではまやらない方がいいパターンの方が結構多かったりもするんですけどこれあえてちょっと拷問的に詰めるとすればただし決断できそうにないっていうのを間違ってるにしてませんかっていうこれを突きつけるんですねでここをがっつり分けてクリアにすると要は正しい間違ってるで言えば正しいって分かってますよね分かってますとてことはこれを決断できなさそうを間違ってるに変換しないでくださいねとじゃ決断できなさそうっていうところにフォーカスさてなぜ決断できないのかっていうところでここで詰めに行くみたいなまこういう拷問詰もありますとで若干ちょっと話ややこしくなってそれるかもしれないですけどまそもそもですね最初の正しい間違ってるっていうのもこれも結構実はむずくてなんかいろんな見方あるというか例えばなんか健康セラピストみたいな人がですねタバコ吸うのは健康にとって外があるよっていうこれ言ってることを正しいと思うんですねでただこれって健康軸で見れば言ってることが正しいっていう話になるんですねで一方でタバコ捨て人でストレス発散軸で見ればタバコ吸うのは正しいっていうなんで結局ここもなんかちょっと軸の話になってくる場合があるというかけどこの場合もこの人はどの軸でどの正義を言ってきてんのかあ確かにこの人は健康軸で言ってきてるからタバコは悪いって言ってんなみたいなこれをストレス発散軸で正しいないで持っていくとすればいやタバコよりもこの葉巻きの方が美味しいよっていうこれストレス発散軸で言うと言ってること新しいとかまこういう話になってくると思うんですねなんでちょっと話それちゃったんですけどなんかそもそもの相手の軸がどっから言ってきてんのかみたいなまここは大前提分かっとかないといけないと思いますとなんで情報が流れてきた時に常にこの4つの要素ですね正しいかどうかできそうかどうかやりたいかどうか自分に合ってるかどうかみたいなここを全部ばらしてそれそれぞれで分けて保有していくんですねでこっから私の実態験なんですけど私大学ワスの野球部でピッチャーやってましてですねでその時にま3年の最初ぐらいにですねなんか大きく劣化したことがあって要はぐちゃぐちゃになって調子悪くなっていったっていうでこれ何かって言うとなんかピッチング工事みたいな人にですねま技術指導されたんですねでその人が言ってたのがボールをとにかく前で話せとでそのピッチャーとバッター感は18m44CMでもう5cm10cmでもピッチャーがボールを前で離されるとバッターは嫌だと差し込まれるとだからとにかくボールを前で話すようにして投げろっていうこういうアドバイスを受けたんですねでこれ聞いた時にこれ今思えばばらして考えるとこの人の言ってることていうのはまず正しいか間違ってるかで言うと正しいんですねロジックとしてでできそうできなさそうで言うとできそうと思ったんすねなんかいきなり150km投げって言われてるわけじゃないんでなんか意識的にちょっとボールを前で離すうん感じかっていうのでなんかこれやったらできそうやなって思ったんですねでやりたいかやりたくないかっていうので言うとやりたいと思ったんですねあなんか前で話してなんかバッター差し込んでみたいなみたいな打ちづらいと思われてみたいなこういう感じですねで最後自分にあってそうかあってなさそうかで言うとこれあってなさそうっていう要は正しいできそうやりたいあってなさそうっていうこういう組み合わせですねでけど自分はできそうでやりたいっていうなんかこの辺の感情論がなんか強く出すぎちゃってあこれ合わないなと思ってすぐパッて離れればよかったんですけどそこでなんかどんどんどんどんこうのめり込んでいっちゃってよりボロボロになっていったっていうこういう経験がありますとでここをなんかシンプルにこうやって頭をクリアにして4つ分けれてたらなんかあんなにぬらんかったんかなみたいなこういうのをちょっと今思ったら思いますとで要はなんかいろんな分野でいい素者に巡り合えたらとかたまたまやってみたものがなんか自分にあってみたいななんかこういうのもなんか運すぎるっていう風に思ってましてまいろんな情報あるんでこん中でなんか死者選択できるやつが結局最強というか汎用性があるみたいなこのなんかたまたま巡り合えたらみたいなこういうのになんか左右されたくないっていう気持ちがなんか個人的にありますとで要はこの4つの組み合わせをそれぞれべこで考えていって例えば結構多いのが言ってることは正しいとお確かに毎朝6時に起きて飛び込み200件やって青汁飲んだら健康になって営業成績も上がりそうやな言ってること正しいとけどできなさうっていうこの正しいできなさうっていうこういう組み合わせがあったりとか正しくてできそうなんだけど個人的にちょっとやりたくねえとかなんかこういう組み合わせとかでこういう4つの組み合わせをバラバラに考えていってクリアにしてじゃあ次このできなさそうとかやりたくないとか合わなそうとかっていうここに焦点を当てていくんですねで正しいけどできなさうってなったらできなさそうに焦点を当ててじゃあなぜできなさそうと思うのかとかじゃあどうやったらじゃあできそうになるのかとか意外とやればできるんじゃねえかとかで次その正しいけどやりたくないってなったらじゃあ自分は何を大事にしてんのかとかじゃじゃあ売上は低くても気持ち良かったらいいのかまそれはそれでいっかとかこの辺のなんか自分が見えてくるというかこれまた考える余地の引き出しストックとして積み上がるというかなんでこのやりたくないに焦点を当てたりだとかできそうにないに焦点を当てて正しいけどできそうにないで結果そのアドバイスを受け入れないっていうのも別にありだと思うんすね現状できそうにないとか現状をやりたくないっていう話なんででそれをキープしてそこまで分かって引き出しの中に1個の材料として置いとくのであればいいんすけどこれをやりたくないできそうにない合わなそうだから間違ってるんだこいつの言ってることはっていうここに行っちゃうと一生シーフードぴよぴよすねなんでこんな感じで1個1個分解してクリアにしていけば主選択の間違いっていうのは少なくなると思いますしま納得して進んでいけるんじゃないでしょうかとまとめると毎日運動することは正しいできなそうやりたくない合わなそうでさすがに克服でできそうにありません以上です'}\n"
     ]
    }
   ],
   "source": [
    "# ベクトル化処理\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "import os\n",
    "from llama_index import SimpleDirectoryReader\n",
    "from llama_index.langchain_helpers.text_splitter import TokenTextSplitter\n",
    "import tiktoken\n",
    "from langchain.schema import Document\n",
    "\n",
    "data_filepath = os.path.join(os.getcwd(), \"raw_data\", )\n",
    "data_list = os.listdir(data_filepath)\n",
    "\n",
    "with open('./raw_data/sou_sera_/y7bC-ylbStY.csv', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    dict_from_csv = {rows[0]: rows[1] for rows in reader}\n",
    "    \n",
    "print(dict_from_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "model_name = model_name=\"intfloat/multilingual-e5-large\"\n",
    "# model_kwargs = {'device': 'cuda'} #GPUでembedding\n",
    "model_kwargs = {'device': 'cpu'} #CPUでembedding\n",
    "hf_embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name = model_name,\n",
    "    model_kwargs = model_kwargs,\n",
    ")\n",
    "\n",
    "faiss_loadlocal = FAISS.load_local(\"./vector_store/sou_sera_/faiss/\", embeddings=hf_embeddings)\n",
    "print(len(faiss_loadlocal.similarity_search(\"お金の稼ぎ方\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
